package rdf

import (
	"context"
	"fmt"
	"io"
	"strconv"
	"strings"
	"sync"

	blk "github.com/DynamoGraph/block"
	"github.com/DynamoGraph/cache"
	"github.com/DynamoGraph/client"
	"github.com/DynamoGraph/db"
	"github.com/DynamoGraph/rdf/ds"
	"github.com/DynamoGraph/rdf/grmgr"
	"github.com/DynamoGraph/rdf/reader"
	"github.com/DynamoGraph/rdf/uuid"
	slog "github.com/DynamoGraph/syslog"
	"github.com/DynamoGraph/util"
)

const (
	// number of nodes in rdf to load in single read
	readBatchSize = 2 // prod: 20
//	processBatchSize = 2 // prod 3 (total 60 concurrent nodes )
)
const (
	I   = "I"
	F   = "F"
	S   = "S"
	Nd  = "Nd"
	SS  = "SS"
	SI  = "SI"
	SF  = "SF"
	LS  = "LS"
	LI  = "LI"
	LF  = "LF"
	LBl = "LbL"
	SBl = "SBl"
)

//
// channels
//
var verifyCh chan verifyNd
var saveCh chan []ds.NV

//
//
var errNodes ds.ErrNodes

type verifyNd struct {
	n     int
	nodes []*ds.Node
}

func syslog(s string) {
	slog.Log("rdfLoader: ", s)
}

func init() {
	errNodes = make(ds.ErrNodes)
	verifyCh = make(chan verifyNd, 2)
	saveCh = make(chan []ds.NV, 2*readBatchSize)
}

// uid PKey of the sname-UID pairs - consumed and populated by the SaveRDFNode()

func Load(f io.Reader) error { // S P O
	//
	// context
	//
	ctx, cancel := context.WithCancel(context.Background())
	//
	var (
		wpStart, wpEnd sync.WaitGroup
		ctxEnd         sync.WaitGroup
		err            error
		n              int // for loop counter
		eof            bool
	)
	//

	//
	// start goroutines
	//
	// check all processes are started
	wpStart.Add(4)
	// check verify and saveNode have finished. Each goroutine is responsible for closing and waiting for all routines they spawn.
	wpEnd.Add(2)
	ctxEnd.Add(2)
	//
	go verify(&wpStart, &wpEnd)
	go saveNode(&wpStart, &wpEnd)
	go uuid.PowerOn(ctx, &wpStart, &ctxEnd)
	go grmgr.PowerOn(ctx, &wpStart, &ctxEnd)
	//
	// wait for processes to start
	//
	wpStart.Wait()
	syslog(fmt.Sprintf("*************** All started "))
	//
	//
	// structures
	//
	rdr, _ := reader.New(f)
	//
	for {
		//
		// make nodes
		//
		nodes := make([]*ds.Node, readBatchSize, readBatchSize)
		// assign pointers
		for i := range nodes {
			nodes[i] = new(ds.Node)
		}
		//
		// read rdf file into nodes
		//
		n, eof, err = rdr.Read(nodes)
		if err != nil {
			// cancel ctx
			err = fmt.Errorf("Read error: %w", err.Error())
			break
		}
		//
		// load channel type and send it
		//
		v := verifyNd{n: n, nodes: nodes}
		fmt.Printf("\n pass to verify: %#v\n\n", v)

		verifyCh <- v

		//
		// exit for if suitable condition
		//
		if n < len(nodes) || eof {
			break
		}
	}

	//	time.Sleep(time.Second * 2)

	close(verifyCh)
	//go processErrors()
	wpEnd.Wait()
	//shutdown uuid & grmgr processes with ctx cancel
	cancel()
	ctxEnd.Wait()

	return err
}

func verify(wpStart *sync.WaitGroup, wpEnd *sync.WaitGroup) { //, wg *sync.WaitGroup) {

	defer wpEnd.Done()
	defer close(saveCh)
	// sync verify's internal goroutines

	wpStart.Done()

	// waitgroups
	var wg sync.WaitGroup
	//
	// concurrent settings for goroutines
	//
	//	unmarshalTrg := grmgr.Trigger{R: routine, C: 5, Ch: make(chan struct{})}
	limiter := grmgr.New("unmarshall", 5)

	syslog("verify started....xx.")
	// the loop will terminate on close of channel
	// each goroutine will finish when it completes - none left hanging
	//	var c int
	for nodes_ := range verifyCh {
		//		c++
		fmt.Println("read from verifyCH : n=", nodes_.n)
		for i := 0; i < nodes_.n; i++ {
			fmt.Println()
			fmt.Printf("****verify Node:  %#v\n", *nodes_.nodes[i])
			fmt.Println()
		}
		nodes := nodes_.nodes

		// unmarshal (& validate) each node in its own goroutine
		for i := 0; i < nodes_.n; i++ {
			if len(nodes[i].Lines) == 0 {
				break
			}
			ii := i
			ty, err := getType(nodes[ii])
			if err != nil {
				fmt.Println(err.Error()) //TODO: handle error
			}
			// first pipeline func. Passes NV data to saveCh and then to database.
			slog.Log("verify: ", fmt.Sprintf("Pass to unmarshal... %d %#v", i, nodes[ii]))

			slog.Log("verify: ", " Send Ask request to limiter.")
			limiter.Ask()
			slog.Log("verify: ", "Verify is waiting from ACK from gcmgr....to proceed to run go routine")
			<-limiter.RespCh()
			slog.Log("verify: ", "ACK from gcmgr....received...")

			wg.Add(1)
			go unmarshalRDF(nodes[ii], ty, &wg, limiter)

		}
		slog.Log("verify: ", fmt.Sprintf("*** Verify back to waiting on veryifyCh"))

	}
	slog.Log("verify: ", "verify at wg.Wait() .....")
	wg.Wait()
	slog.Log("verify: ", "verify exited.....")

}

// type TyAttrD struct {
// 	Name string // Attribute Identfier
// 	DT   string // Attribute Data - derived. ??
// 	C    string // Attribute short identifier
// 	Ty   string // For abstract attribute types the type it respresents e.g "Person"
// 	P    string // data partition (aka shard) containing attribute
// 	N    bool   // true: nullable (attribute may not exist) false: not nullable
// 	Pg   bool   // true: propagate scalar data to parent
// }
func unmarshalRDF(node *ds.Node, ty blk.TyAttrBlock, wg *sync.WaitGroup, lmtr grmgr.Limiter) {
	defer wg.Done()

	genSortK := func(ty blk.TyAttrD) string {
		var s strings.Builder

		if ty.DT == "Nd" {
			if len(ty.P) == 0 {
				s.WriteString("G#:")
			} else {
				s.WriteString(ty.P)
				s.WriteString("#G#:")
			}
			s.WriteString(ty.C)
		} else {
			s.WriteString(ty.P)
			s.WriteString("#:")
			s.WriteString(ty.C)
		}
		return s.String()
	}

	slog.Log("unmarshalRDF", "Entered unmarshalRDF. About to lmtr.StartR()")
	lmtr.StartR()
	defer lmtr.EndR()

	grmgr.StartCh <- lmtr.Routine()

	//localCh := make(chan util.UID)

	// fmt.Println("len node.Lines: ", len(node.Lines))
	// fmt.Println("tyX: ", ty)
	// check all not null types are defined
	// check n.Obj ect value is correct type for attribute

	// accumulate predicate (spo) n.Obj ect values in the following map
	type info struct {
		value interface{}
		name  string
		dt    string
		sortk string
	}
	var attr map[string]*info
	attr = make(map[string]*info)
	//
	var nv []ds.NV // AttributName-Dynamo-Value

	// find predicate in Lines matching type attribute name in ty'

	for _, v := range ty {
		var found bool
		syslog(fmt.Sprintf("Find Ty %s", v.Name))
		//	fmt.Println("node.Lines: ", len(node.Lines), node.Lines)

		for _, n := range node.Lines {

			if !strings.EqualFold(v.Name, n.Pred) {
				continue
			}
			found = true

			switch v.DT {
			case I:
				// check n.Obj ect can be coverted to int

				i, err := strconv.Atoi(n.Obj)
				if err != nil {
					err := fmt.Errorf("expected Integer %s ", n.Obj)
					node.Err = append(node.Err, err)
					continue
				}
				attr[v.Name] = &info{value: i, dt: v.DT}

			case F:
				// check n.Obj ect can be converted to float
				attr[v.Name] = &info{value: n.Obj, dt: v.DT}
				//attr[v.Name] = n.Obj // keep float as string as Dynamodb transport it as string

			case S:
				// check n.Obj ect can be converted to float

				//attr[v.Name] = n.Obj
				attr[v.Name] = &info{value: n.Obj, dt: v.DT}

			case SS:

				if a, ok := attr[v.Name]; !ok {
					ss := make([]string, 1)
					ss[0] = n.Obj
					attr[v.Name] = &info{value: ss, dt: v.DT}
				} else {
					if ss, ok := a.value.([]string); !ok {
						err := fmt.Errorf("Conflict with SS type at line %d", n.N)
						node.Err = append(node.Err, err)
					} else {
						syslog(fmt.Sprintf("Add to SS . [%s]", n.Obj))
						ss = append(ss, n.Obj)
						attr[v.Name].value = ss
					}
				}

			// case SBl:
			// case SB:
			// case LBl:
			// case LB:

			case LS:
				if a, ok := attr[v.Name]; !ok {
					ss := make([]string, 1)
					ss[0] = n.Obj
					attr[v.Name] = &info{value: ss, dt: v.DT}
					//	attr[v.Name] = ss
				} else {
					if ls, ok := a.value.([]string); !ok {
						err := fmt.Errorf("Conflict with SS type at line %d", n.N)
						node.Err = append(node.Err, err)
					} else {
						ls = append(ls, n.Obj)
						attr[v.Name].value = ls
					}
				}

			case LI:
				if a, ok := attr[v.Name]; !ok {
					ss := make([]int, 1)
					i, err := strconv.Atoi(n.Obj)
					if err != nil {
						err := fmt.Errorf("expected Integer %s", n.Obj)
						node.Err = append(node.Err, err)
						continue
					}
					ss[0] = i // n.Obj  int
					//attr[v.Name] = ss
					attr[v.Name] = &info{value: ss, dt: v.DT}
				} else {
					if li, ok := a.value.([]int); !ok {
						err := fmt.Errorf("Conflict with SS type at line %d", n.N)
						node.Err = append(node.Err, err)
					} else {
						i, err := strconv.Atoi(n.Obj)
						if err != nil {
							err := fmt.Errorf("expected Integer %s", n.Obj)
							node.Err = append(node.Err, err)
							continue
						}
						li = append(li, i)
						attr[v.Name].value = li
					}
				}

			case Nd:

				// need to convert n.Obj  value of SName to UID
				if a, ok := attr[v.Name]; !ok {
					ss := make([]string, 1)
					ss[0] = n.Obj
					//attr[v.Name] = ss
					attr[v.Name] = &info{value: ss, dt: v.DT}
					//addEdgesCh<-
				} else {
					if nd, ok := a.value.([]string); !ok {
						err := fmt.Errorf("Conflict with SS type at line %d", n.N)
						node.Err = append(node.Err, err)
					} else {
						nd = append(nd, n.Obj)
						attr[v.Name].value = nd
					}
				}

				//	addEdgesCh<-
			}
			//
			// generate sortk key
			//
			at := attr[v.Name]
			at.sortk = genSortK(v)
		}
		//
		//
		//
		if !found {
			if !v.N && v.DT != "Nd" {
				err := fmt.Errorf("Not null type attribute %q must be specified ", v.Name)
				node.Err = append(node.Err, err)
			}
		}
		if len(node.Err) > 0 {
			fmt.Println("******** return on node.Err ", len(node.Err), node.Err[0].Error())
			return
		}
		// for _, v := range nv {
		// 	fmt.Println("[*** ]NV: ", v)
		// }
	}
	//
	// unmarshal attr into NV -except Nd types, handle in next for
	//
	var addTy = true
	for k, v := range attr {
		//
		if v.dt == Nd {
			continue
		}
		if addTy {
			//
			// add type to NV
			//
			e := ds.NV{Sortk: "A#T", SName: node.ID, Value: node.TyName, DT: "ty"}
			syslog(fmt.Sprintf("Add Type to NV........................... %#v\n", e))
			nv = append(nv, e)
			addTy = false
		}

		e := ds.NV{Sortk: v.sortk, Name: k, SName: node.ID, Value: v.value, DT: v.dt}
		nv = append(nv, e)
	}
	//
	// check all uid-predicate types (DT="Nd") have an NV entry - as this simplies later processing if one is guaranteed to exist even if not originally defined in RDF file
	//
	for _, v := range ty {
		if v.DT == Nd {
			// if _, ok := attr[v.Name]; ok {
			// 	continue
			// }
			// create empty item
			value := []string{"__"}
			e := ds.NV{Sortk: genSortK(v), Name: v.Name, SName: "__", Value: value, DT: Nd}
			nv = append(nv, e)
		}
	}
	//
	//  build list of attachNodes (in uuid pkg) to be processed after all other tuples have been added to db
	//
	for _, v := range attr {
		if v.dt == "Nd" {
			x := v.value.([]string)
			for _, s := range x {
				uuid.EdgesCh <- uuid.Edges{CSn: node.ID, PSn: s, Sortk: v.sortk}
			}
		}
	}
	//
	// pass NV onto database goroutine if no errors detected
	//
	if len(node.Err) == 0 {
		//	for i, v := range nv {
		syslog(fmt.Sprintf("send on saveCh: nv: %#v", nv))
		saveCh <- nv

	} else {
		node.Lines = nil
		errNodes[node.ID] = node
	}
	//
	// acknowledge end to grmgr
	//
	// slog.Log("unmarshal: ", "Send End on channel grmgr.EndCh")
	// grmgr.EndCh <- lmtr.Routine()
	slog.Log("unmarshalRDF", "Exit  unmarshalRDF. ")
}

func saveNode(wpStart *sync.WaitGroup, wpEnd *sync.WaitGroup) {

	defer wpEnd.Done()

	var wg sync.WaitGroup

	syslog("saveNode started......")
	wpStart.Done()
	syslog("define saveNode limiter......")
	//
	// define goroutine limiters
	//
	limiterSave := grmgr.New("saveNode", 2)

	// upto 5 concurrent save routines
	var c int
	for nv := range saveCh {
		c++
		slog.Log("saveNode: ", fmt.Sprintf("read from saveCH channel %d ", c))
		limiterSave.Ask()
		<-limiterSave.RespCh()
		slog.Log("saveNode: ", "limiter has ACK and will start goroutine...")

		wg.Add(1)
		go db.SaveRDFNode(nv, &wg, limiterSave)

	}
	syslog("saveNode  waiting on ASaveRDFNodettachNode to finish")
	wg.Wait()
	syslog("saveNode finished waiting...exiting")

	limiterAttach := grmgr.New("nodeAttach", 3)
	// retrieve attach node pairs from uuid.edges via channel uuid.AttachNodeCh
	uuid.AttachCh <- struct{}{}
	c = 0
	for {
		c++
		n := <-uuid.AttachNodeCh
		if string(n.Cuid) == "eol" {
			break
		}
		slog.Log("attachNode: ", fmt.Sprintf("read from AttachNodeCh channel %d now ASK limiter", c))

		limiterAttach.Ask()
		<-limiterAttach.RespCh()

		slog.Log("attachNode: ", "limiter has ACK and will start goroutine...")

		wg.Add(1)
		slog.Log("AttachNode: ", fmt.Sprintf("goroutine about to start %d ", c))
		go client.AttachNode(util.UID(n.Cuid), util.UID(n.Puid), n.Sortk, &wg, limiterAttach)
	}
	syslog("saveNode  waiting on AttachNode to finish")
	wg.Wait()
	syslog("saveNode finished waiting...exiting")
}

func getType(node *ds.Node) (blk.TyAttrBlock, error) {

	// TODO - replace with goroutine + channel req/resp

	type loc struct {
		sync.Mutex
	}
	var ll loc
	syslog(".  getType..")

	// is there a type defined
	if len(node.TyName) == 0 {
		node.Err = append(node.Err, fmt.Errorf("No type defined for %s", node.ID))
	}
	syslog(fmt.Sprintf("node.TyName : [%s]", node.TyName))
	ll.Lock()
	ty, err := cache.FetchType(node.TyName)
	ll.Unlock()
	if err != nil {
		return nil, err
	}
	return ty, nil
}
